{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import dotenv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv('.env') \n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq(api_key=groq_api_key)\n",
    "MODEL = 'llama-3.3-70b-versatile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11715/2214929945.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/home/thangcn/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo vector database với FAISS\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_aio\",\n",
    "            \"description\": \"Trả lời câu hỏi dựa trên dữ liệu từ tài liệu AIO PDF (ví dụ: AI Agent là gì)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Câu hỏi của người dùng cần trả lời\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"question\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_billionares\",\n",
    "            \"description\": \"Trả lời câu hỏi dựa trên dữ liệu từ tài liệu Billionares PDF (ví dụ: Có bao nhiêu tỷ phú ở Mỹ)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Câu hỏi của người dùng về tỷ phú\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"question\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_economic\",\n",
    "            \"description\": \"Trả lời câu hỏi dựa trên dữ liệu từ tài liệu Economic PDF (về kinh tế và tài chính)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Câu hỏi của người dùng về kinh tế\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"question\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'rag_aio', 'description': 'Trả lời câu hỏi dựa trên dữ liệu từ tài liệu AIO PDF (ví dụ: AI Agent là gì)', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string', 'description': 'Câu hỏi của người dùng cần trả lời'}}, 'required': ['question']}}}, {'type': 'function', 'function': {'name': 'rag_billionares', 'description': 'Trả lời câu hỏi dựa trên dữ liệu từ tài liệu Billionares PDF (ví dụ: Có bao nhiêu tỷ phú ở Mỹ)', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string', 'description': 'Câu hỏi của người dùng về tỷ phú'}}, 'required': ['question']}}}, {'type': 'function', 'function': {'name': 'rag_economic', 'description': 'Trả lời câu hỏi dựa trên dữ liệu từ tài liệu Economic PDF (về kinh tế và tài chính)', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string', 'description': 'Câu hỏi của người dùng về kinh tế'}}, 'required': ['question']}}}]\n"
     ]
    }
   ],
   "source": [
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "# rerank search results\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def retrieve_and_re_rank_advanced(vector_db, query, k=10):\n",
    "    # Lấy kết quả từ Vector Database\n",
    "    docs_with_scores = vector_db.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    # Chuẩn bị dữ liệu cho Cross-Encoder\n",
    "    doc_texts = [doc.page_content for doc, _ in docs_with_scores]\n",
    "    pairs = [[query, doc] for doc in doc_texts]\n",
    "    \n",
    "    # Dùng Cross-Encoder để đánh giá lại\n",
    "    rerank_scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    # Sắp xếp lại theo score mới\n",
    "    ranked_docs = sorted(zip(doc_texts, rerank_scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    results = [doc for doc, _ in ranked_docs]\n",
    "    scores = [score for _, score in ranked_docs]\n",
    "    \n",
    "    return results, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_aio(question: str):\n",
    "    vector_db = FAISS.load_local('/home/thangcn/Downloads/datn/faiss_db/pdf_aio', embeddings, allow_dangerous_deserialization=True)\n",
    "    retrieved_docs, scores = retrieve_and_re_rank_advanced(vector_db, question)\n",
    "        # Gửi yêu cầu đến mô hình Groq\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that utilizes retrieved information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{retrieved_docs[0]}\\n\\nQuestion: {question}\"},\n",
    "        ],\n",
    "        model= MODEL,\n",
    "    )\n",
    "    # print(chat_completion.choices[0].message.content)\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def rag_billionares(question: str):\n",
    "    vector_db = FAISS.load_local('/home/thangcn/Downloads/datn/faiss_db/pdf_billionares', embeddings, allow_dangerous_deserialization=True)\n",
    "    retrieved_docs, scores = retrieve_and_re_rank_advanced(vector_db, question)\n",
    "        # Gửi yêu cầu đến mô hình Groq\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that utilizes retrieved information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{retrieved_docs[0]}\\n\\nQuestion: {question}\"},\n",
    "        ],\n",
    "        model= MODEL,\n",
    "    )\n",
    "    # print(chat_completion.choices[0].message.content)\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def rag_economic(question: str):\n",
    "    vector_db = FAISS.load_local('/home/thangcn/Downloads/datn/faiss_db/pdf_economic', embeddings, allow_dangerous_deserialization=True)\n",
    "    retrieved_docs, scores = retrieve_and_re_rank_advanced(vector_db, question)\n",
    "        # Gửi yêu cầu đến mô hình Groq\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that utilizes retrieved information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{retrieved_docs[0]}\\n\\nQuestion: {question}\"},\n",
    "        ],\n",
    "        model= MODEL,\n",
    "    )\n",
    "    # print(chat_completion.choices[0].message.content)\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a function calling LLM that uses the data extracted from the functions to answer questions around mutual funds, UPI transactions, health insurance policies, and cash loans.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # ChatCompletionMessage(\n",
    "    #     content=None, \n",
    "    #     role='assistant', \n",
    "    #     function_call=None, \n",
    "    #     reasoning=None, \n",
    "    #     tool_calls=[\n",
    "    #         ChatCompletionMessageToolCall(\n",
    "    #             id='call_zd18', \n",
    "    #             function=Function(arguments='{\"transaction_id\":\"TX123\"}', name='upi'), \n",
    "    #             type='function'\n",
    "    #         )\n",
    "    #     ]\n",
    "    # )\n",
    "    # print(response_message)\n",
    "    # print('-' * 100)\n",
    "    if tool_calls:\n",
    "        # try:\n",
    "        available_functions = {\n",
    "            \"rag_aio\": rag_aio,\n",
    "            \"rag_billionares\": rag_billionares,\n",
    "            \"rag_economic\": rag_economic\n",
    "        }\n",
    "\n",
    "        messages.append(response_message)\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            print(function_name)\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(**function_args)\n",
    "            \n",
    "            messages.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            })\n",
    "            \n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        final_response = second_response.choices[0].message.content\n",
    "        # except Exception as e:\n",
    "        #     return \"Sorry I'm not able to answer that question\"\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        messages.append(response_message)\n",
    "        final_response = response.choices[0].message.content\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_economic\n",
      "Tôi xin lỗi vì không có thông tin chính xác về xuất khẩu của Việt Nam sang Mỹ trong năm 2022. Tuy nhiên, theo số liệu của Tổng cục Thống kê Việt Nam, xuất khẩu của Việt Nam sang Mỹ trong năm 2022 đạt khoảng 123,86 tỷ USD. Đây là thông tin được công bố trên trang web của Tổng cục Thống kê Việt Nam.\n"
     ]
    }
   ],
   "source": [
    "input = \"Nam 2022 Viet Nam xuat khau sang My bao nhieu USD\"\n",
    "response = run_conversation(input)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
